# AI Driver ğŸš—

AI Driver is an open-source, educational research project focused on **learning autonomous driving behaviors through reinforcement learning** using lightweight simulation environments such as `highway-env`.

Rather than aiming to build a full self-driving system, the project explores **how driving capabilities can be progressively learned, evaluated, and composed**, starting from basic parking maneuvers and advancing toward pointâ€‘toâ€‘point navigation.

---

## ğŸ“‹ Table of Contents

* [Overview](#overview)
* [Learning Approach](#learning-approach)
* [Project Goals](#project-goals)
* [Roadmap](#roadmap)
* [Installation](#installation)
* [Usage](#usage)
* [Project Structure](#project-structure)
* [Contributing](#contributing)
* [License](#license)
* [Documentation](#documentation)

---

## ğŸ¯ Overview

AI Driver explores autonomous driving as a **progressive learning problem**.

Instead of endâ€‘toâ€‘end autonomy, the project is structured as a sequence of increasingly complex scenarios:

* Goalâ€‘conditioned parking
* Parking with obstacles
* Controlled road navigation
* Trafficâ€‘rule compliance
* Scenarioâ€‘based driving (roundabouts, highways)
* Highâ€‘level navigation from Point A to Point B

Each stage is intentionally **small, interpretable, and reproducible**, allowing close inspection of learning dynamics and failure modes.

The entire journey is documented as a **public LinkedIn series**, highlighting design decisions, tradeâ€‘offs, and lessons learned while building autonomous driving agents.

---

## ğŸ§  Learning Approach

AI Driver is built using **reinforcement learning (RL)**, where an agent learns driving behaviors through interaction with a simulated environment.

The project follows a layered autonomy stack:

1. **Lowâ€‘level control** â€“ steering, throttle, braking
2. **Goalâ€‘conditioned tasks** â€“ e.g. parking in a target pose
3. **Scenario learning** â€“ intersections, roundabouts, highways
4. **Highâ€‘level navigation** â€“ route planning and execution

Early stages focus on **continuous control** and **goalâ€‘conditioned RL**, using algorithms such as:

* SAC (Soft Actorâ€‘Critic)
* PPO (Proximal Policy Optimization)
* HER (Hindsight Experience Replay) for sparseâ€‘reward tasks

The emphasis is on **understanding how and why agents learn**, not only on final performance.

---

## ğŸ¯ Project Goals

The longâ€‘term objective is to explore how autonomous driving capabilities can be progressively learned and composed, including:

* Reaching a target destination on a map
* Executing parking maneuvers
* Following lanes and controlling speed
* Respecting basic traffic rules
* Handling structured road scenarios
* Making safe, smooth, and efficient driving decisions

This project prioritizes **clarity, realism, and learning value** over completeness.

---

## ğŸ—ºï¸ Roadmap

Each phase is intentionally scoped to remain lightweight and focused.

### Phase 1: Foundation âœ… (In Progress)

* [x] Project setup
* [x] Environment configuration
* [x] Parking environment baseline
* [x] Random agent benchmark

### Phase 2: Parking & Obstacles

* [x] Goalâ€‘conditioned parking (empty lot)
    ```bash
    python src/evaluation/evaluate_parking.py --model-path models/parking/sac_her_20251216_222821/best/best_model.zip --render --episodes 10
    ```
* [ ] Parking with static obstacles
* [ ] Parking with constrained space
* [ ] Evaluation metrics and success rate

### Phase 3: Road Navigation

* [ ] Basic road following
* [ ] Lane keeping
* [ ] Speed control
* [ ] Simple turns

### Phase 4: Traffic Rules

* [ ] Stop signs
* [ ] Yield behavior
* [ ] Traffic lights
* [ ] Rightâ€‘ofâ€‘way logic

### Phase 5: Complex Scenarios

* [ ] Roundabouts
* [ ] Highway merging
* [ ] Lane changes
* [ ] Overtaking

### Phase 6: Pointâ€‘toâ€‘Point Navigation

* [ ] Map generation or loading
* [ ] Highâ€‘level path planning
* [ ] Route following
* [ ] Endâ€‘toâ€‘end navigation experiments

---

## ğŸš€ Installation

### Prerequisites

* Python 3.8+
* pip

### Setup

```bash
git clone https://github.com/yourusername/AiDriver.git
cd AiDriver
python -m venv .venv
```

Activate the environment:

```bash
# Windows
.venv\Scripts\activate

# macOS / Linux
source .venv/bin/activate
```

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ’» Usage

### Sanity Check

Verify that the environment runs correctly:

```bash
python sanity_run.py
```

This launches a parking environment with a random agent.

### Random Agent Benchmark

Run a baseline benchmark with a random agent to establish performance metrics:

```bash
python run_benchmark.py --episodes 100
```

Options:
- `--episodes N`: Number of episodes to run (default: 100)
- `--render`: Render the environment during evaluation
- `--seed N`: Set random seed for reproducibility
- `--output PATH`: Output file path (default: `data/logs/random_agent_benchmark.json`)
- `--quiet`: Suppress progress output

The benchmark collects metrics including:
- Success rate
- Mean reward and standard deviation
- Average episode length
- Per-episode detailed metrics

Results are saved to a JSON file for comparison with trained agents.

### Training

Training scripts are under active development.

The first milestone focuses on training a **goalâ€‘conditioned parking agent** using reinforcement learning. Detailed commands and configurations will be documented as each phase is completed.

---

## ğŸ“ Project Structure

```
AiDriver/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ sanity_run.py
â”œâ”€â”€ run_benchmark.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ random_agent.py
â”‚   â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ benchmark.py
â”‚   â”‚   â””â”€â”€ run_benchmark.py
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ env_config.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ parking/
â”‚   â”œâ”€â”€ parking_obstacles/
â”‚   â””â”€â”€ navigation/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ maps/
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ experiments/
â”‚
â”œâ”€â”€ tests/
â””â”€â”€ docs/
```

---

## ğŸ¤ Contributing

Contributions are welcome. This project is intentionally open to experimentation and discussion.

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Open a Pull Request

Please follow PEPâ€‘8 style guidelines and include documentation where appropriate.

---

## ğŸ“„ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ“š Documentation

* [highwayâ€‘env Documentation](https://highway-env.readthedocs.io/)
* LinkedIn Series (coming soon)

---

## ğŸ™ Acknowledgments

* `highway-env` â€“ lightweight driving environments for RL research
* OpenAI Gym / Gymnasium â€“ reinforcement learning interfaces

---

**Note**: This project is developed as a public learning journey. Progress, failures, and design decisions are intentionally shared as part of the process.
